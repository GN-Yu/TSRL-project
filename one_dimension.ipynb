{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPOxld2cH3qM0sNnDmMCxUa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GN-Yu/TSRL-project/blob/main/one_dimension.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import psutil\n",
        "import tensorflow as tf\n",
        "import subprocess\n",
        "\n",
        "# Function to execute shell command and return output\n",
        "def run_shell_command(cmd):\n",
        "    return subprocess.run(cmd, stdout=subprocess.PIPE, shell=True).stdout.decode('utf-8').strip()\n",
        "\n",
        "# Check CPU\n",
        "cpu_info = run_shell_command(\"cat /proc/cpuinfo | grep 'model name' | uniq\")\n",
        "print(\"CPU:\", cpu_info.split(\":\")[1].strip() if cpu_info else \"Not available\")\n",
        "\n",
        "# Number of CPU Cores\n",
        "num_cores = os.cpu_count()\n",
        "print(\"Number of CPU cores:\", num_cores)\n",
        "\n",
        "# Total RAM\n",
        "ram_info = psutil.virtual_memory()\n",
        "total_ram = ram_info.total / (1024 ** 3)  # Convert bytes to GB\n",
        "print(f\"Total RAM : {total_ram} GB\")\n",
        "\n",
        "# Check GPU\n",
        "gpu_info = !nvidia-smi --query-gpu=gpu_name,memory.total --format=csv\n",
        "if gpu_info and len(gpu_info) > 1:\n",
        "    gpu_name = gpu_info[1].split(',')[0]\n",
        "    gpu_memory_mib = float(gpu_info[1].split()[2])  # Extract the memory in MiB\n",
        "    gpu_memory_gb = gpu_memory_mib / 1024\n",
        "    print(f\"GPU: {gpu_name}, {gpu_memory_gb} GB\")\n",
        "else:\n",
        "    print(\"GPU: Not available\")\n",
        "\n",
        "# TensorFlow info\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(\"TensorFlow GPU Availability:\", tf.test.is_gpu_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgd5Aprvn-O3",
        "outputId": "bf7d5116-69ab-4953-f595-c5d88fd61444"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "Number of CPU cores: 2\n",
            "Total RAM : 12.674789428710938 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-f4feeca38a4f>:35: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: Tesla T4, 15.0 GB\n",
            "TensorFlow version: 2.15.0\n",
            "TensorFlow GPU Availability: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xVz5AilONonQ"
      },
      "outputs": [],
      "source": [
        "# organize files\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/content/drive/MyDrive/TSRL_project'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Set random seed\n",
        "SEED = 2023\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)"
      ],
      "metadata": {
        "id": "BeEgglCXOEEa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_brownian_motion(num_trajectories, time_steps):\n",
        "    \"\"\"\n",
        "    Function to sample Brownian motion for the specified number of trajectories and time steps.\n",
        "\n",
        "    :param num_trajectories: The number of trajectories to simulate.\n",
        "    :param time_steps: A numpy array of time steps.\n",
        "    :return: A numpy array of shape (num_trajectories, len(time_steps)-1) representing the Brownian increments.\n",
        "    \"\"\"\n",
        "    # Calculate time intervals (delta_t) as differences between consecutive time steps\n",
        "    delta_t = np.diff(time_steps)\n",
        "\n",
        "    # Sample Brownian increments ∆W for each time interval and each trajectory\n",
        "    brownian_increments = np.random.normal(0, np.sqrt(delta_t), (num_trajectories, len(delta_t)))\n",
        "\n",
        "    return brownian_increments\n",
        "\n",
        "def sample_initial_states(num_samples):\n",
        "    # Implement initial state sampling here\n",
        "    pass\n",
        "\n"
      ],
      "metadata": {
        "id": "hVDp3bo8QXp9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Levy jump func in tuple format\n",
        "\n",
        "# def sample_levy_jumps(num_trajectories, lambda_param, mu, sigma, time_horizon):\n",
        "#     \"\"\"\n",
        "#     Function to sample jumps from a Lévy process for the specified number of trajectories.\n",
        "\n",
        "#     :param num_trajectories: The number of trajectories to simulate.\n",
        "#     :param lambda_param: The intensity parameter λ of the Poisson process.\n",
        "#     :param phi_function: The density function ϕ(z) of the jump sizes.\n",
        "#     :param time_horizon: The total time horizon T.\n",
        "#     :return: A list containing tuples (jump_times, jump_sizes) for each trajectory.\n",
        "#     \"\"\"\n",
        "#     jumps = []\n",
        "\n",
        "#     for _ in range(num_trajectories):\n",
        "#         # Step (a): Generate a sequence of exponential distributions with parameter λ\n",
        "#         exponential_samples = np.random.exponential(1/lambda_param, 1000)  # Generate a large number of samples\n",
        "\n",
        "#         # Step (b): Compute the cumulative sum to get the arrival times of the Poisson process\n",
        "#         arrival_times = np.cumsum(exponential_samples)\n",
        "#         arrival_times = arrival_times[arrival_times <= time_horizon]  # Filter times beyond the time horizon\n",
        "\n",
        "#         # Step (c): Sample from ϕ(z) for each arrival time to get the jump sizes\n",
        "#         jump_sizes = np.array([np.random.normal(mu, sigma) for _ in arrival_times])\n",
        "\n",
        "#         jumps.append((arrival_times, jump_sizes))\n",
        "\n",
        "#     return jumps\n",
        "\n",
        "# # Example usage\n",
        "# lambda_param = 0.3  # Intensity parameter λ of the Poisson process\n",
        "# time_horizon = 1    # Total time horizon T\n",
        "# M = 1000  # Number of samples/trajectories\n",
        "# mu = 0.4\n",
        "# sigma = 0.25\n",
        "\n",
        "# np.random.seed(SEED)\n",
        "\n",
        "# # Simulate jumps for a specific number of trajectories\n",
        "# levy_jumps = sample_levy_jumps(M, lambda_param, mu, sigma, time_horizon)\n",
        "\n",
        "# # Example output of the first trajectory's jumps\n",
        "# for i in range(10):\n",
        "#   print(levy_jumps[i])  # (array of arrival times, array of jump sizes)\n",
        "\n",
        "# print(len(levy_jumps))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "aXeV-LsjBmaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_levy_jumps(num_trajectories, lambda_param, mu, sigma, time_horizon, max_jumps=1000):\n",
        "    \"\"\"\n",
        "    Function to sample jumps from a Lévy process for the specified number of trajectories.\n",
        "    Returns a 3D NumPy array with shape (num_trajectories, max_jumps, 2), where the last dimension\n",
        "    contains arrival times and jump sizes respectively.\n",
        "\n",
        "    :param num_trajectories: The number of trajectories to simulate.\n",
        "    :param lambda_param: The intensity parameter λ of the Poisson process.\n",
        "    :param mu: Mean of the normal distribution for jump sizes.\n",
        "    :param sigma: Standard deviation of the normal distribution for jump sizes.\n",
        "    :param time_horizon: The total time horizon T.\n",
        "    :param max_jumps: Maximum number of jumps to consider for each trajectory.\n",
        "    :return: A 3D NumPy array containing (arrival_times, jump_sizes) for each trajectory.\n",
        "    \"\"\"\n",
        "    all_jumps = np.zeros((num_trajectories, max_jumps, 2))\n",
        "\n",
        "    for i in range(num_trajectories):\n",
        "        # Generate a sequence of exponential distributions with parameter λ\n",
        "        exponential_samples = np.random.exponential(1/lambda_param, max_jumps)\n",
        "\n",
        "        # Compute the cumulative sum to get the arrival times of the Poisson process\n",
        "        arrival_times = np.cumsum(exponential_samples)\n",
        "        valid_indices = arrival_times <= time_horizon\n",
        "        arrival_times = arrival_times[valid_indices]\n",
        "\n",
        "        # Sample from the normal distribution for each arrival time to get the jump sizes\n",
        "        jump_sizes = np.random.normal(mu, sigma, arrival_times.size)\n",
        "\n",
        "        all_jumps[i, :arrival_times.size, 0] = arrival_times\n",
        "        all_jumps[i, :arrival_times.size, 1] = jump_sizes\n",
        "\n",
        "    return all_jumps\n",
        "\n",
        "\n",
        "# # Example usage\n",
        "# lambda_param = 0.3  # Intensity parameter λ of the Poisson process\n",
        "# time_horizon = 1    # Total time horizon T\n",
        "# M = 1000  # Number of samples/trajectories\n",
        "# mu = 0.4\n",
        "# sigma = 0.25\n",
        "\n",
        "# np.random.seed(SEED)\n",
        "\n",
        "# # Simulate jumps for a specific number of trajectories\n",
        "# levy_jumps = sample_levy_jumps(M, lambda_param, mu, sigma, time_horizon)\n",
        "\n",
        "# # Example output of the first trajectory's jumps\n",
        "# for i in range(10):\n",
        "#   print(levy_jumps[i])  # (array of arrival times, array of jump sizes)\n",
        "\n",
        "# print(len(levy_jumps))"
      ],
      "metadata": {
        "id": "8gzLZHcv187u"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import norm\n",
        "\n",
        "z = 0.5 # location to evaluate\n",
        "\n",
        "# Using scipy.stats\n",
        "phi = norm.pdf(z, loc=mu, scale=sigma)\n",
        "\n",
        "print(phi)"
      ],
      "metadata": {
        "id": "o3yAc_n2sbky",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ae45206-fa2b-44d0-a3f8-cda490a32ba9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.4730805612132936\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_neural_network(input_dim, layer_width=25, output_dim=2):\n",
        "    # Define the input layer\n",
        "    inputs = tf.keras.Input(shape=(input_dim,))\n",
        "\n",
        "    # First linear layer\n",
        "    x = tf.keras.layers.Dense(layer_width, activation='tanh')(inputs)\n",
        "\n",
        "    # Add five residual blocks\n",
        "    for _ in range(5):\n",
        "        y = tf.keras.layers.Dense(layer_width, activation='tanh')(x)\n",
        "        y = tf.keras.layers.Dense(layer_width, activation='tanh')(y)\n",
        "        x = tf.keras.layers.Add()([x, y])\n",
        "\n",
        "    # Final linear layer\n",
        "    outputs = tf.keras.layers.Dense(output_dim)(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Use GPU for model creation\n",
        "with tf.device('/GPU:0'):\n",
        "    model = create_neural_network(input_dim=2)\n",
        "\n",
        "# Prepare input data (example)\n",
        "input_data = np.array([[0.5, -0.5],\n",
        "                       [1.0, 0.0],\n",
        "                       [-0.5, 0.5]])\n",
        "\n",
        "# Make predictions\n",
        "output_data = model.predict(input_data)\n",
        "\n",
        "print(\"Output Data:\")\n",
        "print(output_data)"
      ],
      "metadata": {
        "id": "dBKB-G3thPfZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ca19c83-ad3d-4c24-84e9-6f7abc3c6e1a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 331ms/step\n",
            "Output Data:\n",
            "[[ 0.27551487  1.1717864 ]\n",
            " [-0.1227932  -0.11135089]\n",
            " [-0.27551487 -1.1717864 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.integrate as integrate\n",
        "from scipy.stats import norm\n",
        "\n",
        "def G_function(x, z):\n",
        "    \"\"\"Define the function G(x, z).\"\"\"\n",
        "    return x * np.exp(z)\n",
        "\n",
        "def normal_pdf(z, mu, sigma):\n",
        "    \"\"\"Normal probability density function.\"\"\"\n",
        "    return (1 / (np.sqrt(2 * np.pi) * sigma)) * np.exp(-((z - mu) ** 2) / (2 * sigma ** 2))\n",
        "\n",
        "def integral_G_phi(x, mu, sigma, G_func, phi_func):\n",
        "    \"\"\"Calculate the integral of G_func(x, z) * phi_func(z) over R.\"\"\"\n",
        "    def integrand(z):\n",
        "        return G_func(x, z) * phi_func(z, mu, sigma)\n",
        "\n",
        "    # Perform the integration over the entire real line\n",
        "    result, _ = integrate.quad(integrand, -500, 500)\n",
        "    return result\n",
        "\n",
        "# Example usage:\n",
        "mu = 0.4\n",
        "sigma = 0.25\n",
        "x = 1  # Example value for x\n",
        "integral = integral_G_phi(x, mu, sigma, G_function, normal_pdf)\n",
        "print(integral)\n"
      ],
      "metadata": {
        "id": "yMBpKrUNrvGa",
        "outputId": "39a73f92-6b0e-475a-98a2-5dfa4c5ff876",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.5391802969357233\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title non-vectorized calcs\n",
        "\n",
        "# np.random.seed(SEED)\n",
        "\n",
        "# # Define Constants\n",
        "\n",
        "# lambda_poisson = 0.3\n",
        "# mu = 0.4\n",
        "# sigma = 0.25\n",
        "\n",
        "# T = 1.0  # Total time\n",
        "# N = 50  # Number of time intervals\n",
        "# # M = 1000  # Number of samples/trajectories\n",
        "# # Iterations = 400  # Number of iterations\n",
        "\n",
        "# # unit tests\n",
        "# M = 5  # Number of samples/trajectories\n",
        "# Iterations = 1  # Number of iterations\n",
        "\n",
        "# initial_learning_rate = 5e-5\n",
        "\n",
        "# # Generate equally spaced time snapshots from 0 to T\n",
        "# time_steps = np.linspace(0, T, N+1)\n",
        "\n",
        "# # Initialize NN model\n",
        "# d = 1 # problem's dimensionality\n",
        "# input_dim = d + 1\n",
        "# with tf.device('/GPU:0'):\n",
        "#   model = create_neural_network(input_dim)\n",
        "\n",
        "\n",
        "# for iteration in range(Iterations):\n",
        "#   brownian_motions = sample_brownian_motion(M, time_steps)\n",
        "#   levy_jumps = sample_levy_jumps(M, lambda_poisson, mu, sigma, T)\n",
        "\n",
        "#   X = [[0 for _ in range(M)] for _ in range(N+1)]\n",
        "#   Y = [[0 for _ in range(M)] for _ in range(N+1)]\n",
        "\n",
        "#   for timestep, time in enumerate(time_steps):\n",
        "#     if timestep == 0:\n",
        "#       X[timestep] = [1 for _ in range(M)]  # Initial value for PIDE\n",
        "#     else:\n",
        "#       timestep_pre = timestep - 1\n",
        "#       time_pre = time_steps[timestep_pre]\n",
        "#       time_diff = time - time_pre\n",
        "\n",
        "#       for trajectory in range(M):\n",
        "#         arrival_times, jump_sizes = levy_jumps[trajectory]\n",
        "#         mask = (arrival_times > time_pre) & (arrival_times <= time)\n",
        "\n",
        "#         X[timestep][trajectory] = X[timestep_pre][trajectory] + G_function(X[timestep_pre][trajectory], jump_sizes[mask]).sum() - time_diff * lambda_poisson * integral_G_phi(X[timestep_pre][trajectory], mu, sigma, G_function, normal_pdf)\n",
        "\n"
      ],
      "metadata": {
        "id": "fU6Q2QUrlRGM",
        "cellView": "form"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "lambda_poisson = 0.3\n",
        "mu = 0.4\n",
        "sigma = 0.25\n",
        "T = 1.0  # Total time\n",
        "N = 50   # Number of time intervals\n",
        "# M = 1000  # Number of samples/trajectories\n",
        "# Iterations = 400  # Number of iterations\n",
        "\n",
        "# unit tests\n",
        "M = 5  # Number of samples/trajectories\n",
        "Iterations = 1  # Number of iterations\n",
        "\n",
        "initial_learning_rate = 5e-5\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Generate equally spaced time snapshots from 0 to T\n",
        "time_steps = np.linspace(0, T, N+1)\n",
        "\n",
        "# Initialize NN model\n",
        "d = 1  # problem's dimensionality\n",
        "input_dim = d + 1\n",
        "with tf.device('/GPU:0'):\n",
        "    model = create_neural_network(input_dim)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "# Function definitions (assumed to be vectorized)\n",
        "# sample_brownian_motion, sample_levy_jumps, G_function, integral_G_phi, normal_pdf\n",
        "\n",
        "for iteration in range(Iterations):\n",
        "    brownian_motions = sample_brownian_motion(M, time_steps)\n",
        "    levy_jumps = sample_levy_jumps(M, lambda_poisson, mu, sigma, T)\n",
        "\n",
        "    # Initialize arrays for X and Y\n",
        "    X = np.zeros((N+1, M))\n",
        "    Y = np.zeros((N+1, M))\n",
        "\n",
        "    # Set initial value for PIDE\n",
        "    X[0, :] = 1\n",
        "\n",
        "    # Iterate over time steps\n",
        "    for timestep in range(1, N+1):\n",
        "        time_pre = time_steps[timestep - 1]\n",
        "        time_diff = time_steps[timestep] - time_pre\n",
        "\n",
        "        # Mask for jumps that occur in the current time interval\n",
        "        masks = (levy_jumps[:, :, 0] > time_pre) & (levy_jumps[:, :, 0] <= time_steps[timestep])\n",
        "\n",
        "        # Vectorized computation of jump contributions for each trajectory\n",
        "        X_timestep = X[timestep - 1, :][:, np.newaxis]  # Reshape X to for broadcasting\n",
        "        jump_contributions = np.sum(G_function(X_timestep, levy_jumps[:, :, 1]) * masks, axis=1)\n",
        "\n",
        "        # Apply integral_G_phi element-wise\n",
        "        integral_contributions = np.array([time_diff * lambda_poisson * integral_G_phi(x, mu, sigma, G_function, normal_pdf) for x in X[timestep - 1, :]])\n",
        "\n",
        "        X[timestep, :] = X[timestep - 1, :] + jump_contributions - integral_contributions\n"
      ],
      "metadata": {
        "id": "yyM_H4IBzjQG"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mAuMwyrNuYEM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}